{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=tiktoken.get_encoding(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\",\"r\") as f:\n",
    "    raw_text=f.read()\n",
    "\n",
    "encoded_text=tokenizer.encode(raw_text)\n",
    "print(len(encoded_text))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 367, 2885, 1464]\n",
      "    [367, 2885, 1464, 1807]\n"
     ]
    }
   ],
   "source": [
    "context_size=4\n",
    "\n",
    "x=encoded_text[:context_size]\n",
    "y=encoded_text[1:context_size+1]\n",
    "   \n",
    "print(x)\n",
    "print(\"   \",y)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] ===> 367\n",
      "[40, 367] ===> 2885\n",
      "[40, 367, 2885] ===> 1464\n",
      "[40, 367, 2885, 1464] ===> 1807\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context=encoded_text[:i]\n",
    "    desired=encoded_text[i]\n",
    "    print(context,\"===>\",desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ===>  H\n",
      "I H ===> AD\n",
      "I HAD ===>  always\n",
      "I HAD always ===>  thought\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = encoded_text[:i]  \n",
    "    desired = encoded_text[i]\n",
    "    print(tokenizer.decode(context), \"===>\", tokenizer.decode([desired]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets and Data Loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets and Dataloader allows us to load data in more effificient manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will implement Data Loader that Fatches the Data Using sliding window approach   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTversion1(Dataset):\n",
    "    def __init__(self,text#text file to be read\n",
    "                 ,tokenizer #byte pair tokenizer\n",
    "                 ,max_length #cotext size\n",
    "                 ,stride):\n",
    "        self.input_ids=[]\n",
    "        self.target_ids=[]\n",
    "        \n",
    "        token_ids=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            input_chunk=token_ids[i:i+max_length]\n",
    "            target_chunk=token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.input_ids[i],self.target_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Dataset loader\n",
    "def create_dataset_Loader_V1(text,batch_size=4#number of CPU cores to use\n",
    "                         ,max_length=256,\n",
    "                         stride=128,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=0#number of CPU threads that we can use simultaneously\n",
    "                         ):\n",
    "    #initialize the tokenizer\n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset=GPTversion1(text,tokenizer,max_length,stride)\n",
    "    dataLoader=DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
    "    return dataLoader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[373, 407, 691, 262]]), tensor([[ 407,  691,  262, 9074]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "with open(\"the-verdict.txt\",\"r\") as f:\n",
    "    raw_text=f.read()\n",
    "dataloader=create_dataset_Loader_V1(raw_text,batch_size=1,max_length=4,\n",
    "                                    stride=1)\n",
    "data_iter=iter(dataloader)\n",
    "first_batch=next(data_iter)\n",
    "print(first_batch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import train model to create Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors =model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32421875 -0.24316406  0.11523438  0.25976562 -0.18847656  0.10595703\n",
      " -0.10205078  0.10693359  0.28710938  0.01428223  0.0100708  -0.20214844\n",
      "  0.19238281  0.07714844 -0.03686523  0.06933594 -0.0013504   0.26757812\n",
      "  0.12011719  0.02746582 -0.0072937  -0.04443359  0.15625     0.10693359\n",
      "  0.1640625  -0.07177734  0.02355957 -0.03930664 -0.05004883 -0.17480469\n",
      " -0.06054688 -0.10839844 -0.17382812  0.01843262  0.14160156 -0.4140625\n",
      " -0.43554688 -0.12792969  0.1484375  -0.04882812 -0.11914062  0.23046875\n",
      "  0.265625    0.10400391  0.27929688  0.06933594 -0.03881836  0.31640625\n",
      " -0.40625     0.05712891 -0.01324463 -0.09960938  0.05737305 -0.18945312\n",
      " -0.15039062  0.23632812 -0.05102539 -0.17871094 -0.21972656  0.14746094\n",
      "  0.16308594  0.04736328 -0.13183594  0.22070312 -0.04003906  0.05517578\n",
      " -0.2734375   0.42773438 -0.25585938  0.06591797  0.05419922 -0.25\n",
      "  0.14453125 -0.00531006 -0.08984375 -0.01312256  0.08349609 -0.203125\n",
      " -0.0022583  -0.25390625  0.08935547  0.08447266  0.27539062  0.2890625\n",
      "  0.00595093 -0.15625     0.00994873  0.29882812 -0.04980469  0.11523438\n",
      "  0.11914062 -0.04052734 -0.05737305 -0.33203125  0.19238281 -0.18359375\n",
      "  0.11132812  0.20410156  0.21582031  0.10302734  0.2734375  -0.23535156\n",
      " -0.09912109  0.16699219  0.09619141  0.17871094 -0.14453125 -0.09472656\n",
      "  0.44140625  0.00062561 -0.11083984 -0.18945312 -0.09912109 -0.01361084\n",
      "  0.10449219  0.12451172 -0.00805664 -0.00817871  0.07861328  0.02722168\n",
      " -0.31445312  0.14160156 -0.11523438 -0.01281738 -0.13085938  0.06787109\n",
      " -0.18847656 -0.01525879  0.00552368  0.16601562  0.12890625 -0.3515625\n",
      "  0.02490234  0.16894531  0.09667969  0.13671875  0.07958984 -0.09228516\n",
      " -0.55859375 -0.25       -0.04248047 -0.27539062  0.14355469  0.02197266\n",
      "  0.05200195  0.01373291  0.2890625  -0.11083984 -0.21582031 -0.07958984\n",
      "  0.11816406  0.02807617 -0.14453125  0.19921875 -0.13085938  0.22265625\n",
      " -0.25       -0.00714111 -0.22753906  0.01940918 -0.06689453  0.05297852\n",
      " -0.11474609 -0.06933594  0.09521484  0.14160156 -0.11230469 -0.046875\n",
      " -0.22753906 -0.01574707 -0.08105469  0.09375    -0.15234375  0.11865234\n",
      " -0.04345703 -0.04760742 -0.05883789 -0.15136719 -0.234375   -0.10107422\n",
      " -0.04833984 -0.24121094 -0.07568359 -0.27539062  0.21582031  0.03710938\n",
      " -0.12304688  0.06445312  0.20996094 -0.07177734 -0.04003906 -0.01879883\n",
      " -0.16015625  0.20703125  0.03027344  0.25390625  0.15722656 -0.32617188\n",
      " -0.08300781 -0.05273438 -0.05102539  0.01324463  0.23925781  0.22558594\n",
      "  0.26171875 -0.03271484  0.10839844 -0.18652344 -0.33007812 -0.2421875\n",
      " -0.00081253  0.10400391 -0.16015625  0.04296875  0.17089844  0.25585938\n",
      " -0.13085938  0.37304688 -0.453125   -0.18945312 -0.09326172 -0.234375\n",
      "  0.07470703  0.22949219 -0.17578125 -0.07763672 -0.33789062  0.03955078\n",
      " -0.140625   -0.3046875  -0.09228516 -0.14648438 -0.07177734 -0.30273438\n",
      " -0.15625    -0.17578125  0.06542969 -0.14746094  0.09912109  0.14355469\n",
      "  0.20703125  0.05639648 -0.10058594 -0.03198242 -0.10693359 -0.03515625\n",
      " -0.11523438  0.09375     0.06689453 -0.01544189 -0.328125    0.25\n",
      " -0.23242188  0.078125   -0.11328125 -0.15136719  0.07519531  0.00762939\n",
      " -0.09033203  0.05249023 -0.02050781 -0.05151367  0.01831055  0.09033203\n",
      "  0.05761719  0.11669922 -0.13769531  0.19335938 -0.04370117  0.359375\n",
      " -0.08398438 -0.03417969  0.00369263  0.1484375   0.08105469 -0.15917969\n",
      "  0.18554688 -0.28515625  0.15917969  0.05615234 -0.07519531  0.10205078\n",
      " -0.01745605  0.125       0.10693359 -0.1484375   0.23535156  0.18261719\n",
      "  0.10546875  0.29492188 -0.35351562  0.01745605  0.03442383 -0.26171875\n",
      "  0.06176758 -0.23242188  0.01696777 -0.00604248 -0.02856445 -0.07275391]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors[\"computers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors[\"king\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5293, -0.4622, -2.5534],\n",
      "        [-1.1552, -1.1755,  0.3494],\n",
      "        [ 1.1887, -0.5188, -0.1132],\n",
      "        [ 0.1112,  0.2234, -0.8278],\n",
      "        [-0.0327,  1.0452,  2.6432]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size=5\n",
    "out_dim=3\n",
    "\n",
    "embedding_layer=torch.nn.Embedding(vocab_size,out_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1552, -1.1755,  0.3494],\n",
      "        [ 1.1887, -0.5188, -0.1132],\n",
      "        [ 0.1112,  0.2234, -0.8278],\n",
      "        [-0.0327,  1.0452,  2.6432]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Embedding:\n",
    "\n",
    "position of words in the vectors also matters the most as the occuarance of the word may create a impact on the meaning of the total sentense\n",
    "\n",
    "example: \n",
    "1) the cat sat on the mat   \n",
    "2) on the mat the cat sat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two type os positional Embedding \n",
    "1) Absolute\n",
    "for each position in the input sequence a unique embedding is added to the tokens embedding to convey it's exact location\n",
    "\n",
    "\n",
    "2) Relative\n",
    "The emphasis is on the relative position or the distance between the token\n",
    "the model learns relationships in terms of how far apart rather than at which exact position\n",
    "Advantage of Relative positional Encoding: Models can generalize better to the sequence of varying length even if it has not seen it before in the training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the types of Embeddings enables LLM's to understand the orders and relationship between the tokens,ensuring most accurate context aware prediction\n",
    "\n",
    "\n",
    "\n",
    "The choice between the Two Depends on the application and the nature of the data to be processed    \n",
    "Absolute Positional Embedding: Suitable when fixed order of tokens  is crusial,such as sequence generation\n",
    "\n",
    "Relative Positional Embedding:It is suitable for task like language modeling over long Sequences ,where same phrase can appear in different part of the Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open AI's GPT model Uses Positional Embedding that are optimized during the training process. This optimization is thre part of training itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size=50257\n",
    "output_dim=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding=torch.nn.Embedding(vector_size,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=4\n",
    "downloader=create_dataset_Loader_V1(raw_text,batch_size=8,max_length=max_length,stride=max_length,shuffle=True,drop_last=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter=iter(downloader)\n",
    "input,output=next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5556, -1.0137, -0.5938,  ...,  0.5493,  0.5578,  0.0538],\n",
      "         [ 0.9017,  0.1570, -1.3037,  ..., -0.3306,  1.5625, -1.3916],\n",
      "         [ 2.0968,  1.2696, -2.2151,  ..., -0.5722, -1.8061, -0.7265],\n",
      "         [ 0.1302, -2.0691, -0.0416,  ...,  1.9144,  0.7264, -0.1596]],\n",
      "\n",
      "        [[-0.4814, -1.8321, -0.4672,  ...,  0.5026, -1.1142,  0.6402],\n",
      "         [ 2.0756, -1.4190,  1.6017,  ..., -2.6732,  0.1429, -2.8014],\n",
      "         [ 1.6733, -0.5374, -0.5912,  ..., -0.7966, -0.7311,  1.7051],\n",
      "         [ 0.5936,  0.1109, -0.9556,  ..., -1.2246,  2.1985, -1.0656]],\n",
      "\n",
      "        [[-0.4814, -1.8321, -0.4672,  ...,  0.5026, -1.1142,  0.6402],\n",
      "         [ 2.2799,  0.9102, -0.6695,  ...,  0.3464, -1.7040, -2.0921],\n",
      "         [ 1.8379, -1.9353, -0.5752,  ...,  0.1207, -0.4134, -0.9853],\n",
      "         [ 0.7345, -1.5084,  0.3634,  ...,  0.9297,  1.6863, -1.6111]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2214, -1.2381, -0.4062,  ..., -0.0651, -0.0430, -0.5761],\n",
      "         [ 0.6183, -1.1724,  0.4823,  ..., -1.3439,  0.6690, -2.2724],\n",
      "         [ 0.5497, -1.8659, -0.0347,  ..., -0.8347, -0.0483,  0.3971],\n",
      "         [ 0.7376, -1.6756, -0.9713,  ...,  0.5181,  0.3354,  0.4569]],\n",
      "\n",
      "        [[-0.5485, -1.2958,  0.0750,  ..., -1.6810,  0.4875, -0.8045],\n",
      "         [-0.0330, -0.4200,  0.0143,  ..., -2.3570,  1.6400, -0.4017],\n",
      "         [-0.0083, -0.8652, -0.4583,  ...,  0.1099,  0.8864, -1.5661],\n",
      "         [ 0.3005, -1.3451, -1.1037,  ...,  1.0218,  1.7734, -1.8850]],\n",
      "\n",
      "        [[-0.4515, -0.7171, -0.9835,  ...,  0.5747, -0.1075, -0.4353],\n",
      "         [ 1.4553, -2.3887,  2.7393,  ..., -2.4939, -0.6967, -1.6353],\n",
      "         [ 1.5284, -1.8807,  0.3047,  ...,  0.5694, -1.2640,  1.7544],\n",
      "         [ 2.0538, -1.5489, -0.8008,  ..., -0.3138,  1.6231, -0.8783]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(input_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding=token_embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6126, -1.1403, -0.5397,  ..., -1.4797,  1.6822, -0.4507],\n",
      "        [ 0.9127, -0.4203,  0.6507,  ...,  0.1688, -0.2156, -1.2880],\n",
      "        [-0.0624, -1.1176, -0.2275,  ..., -0.3903, -0.5160,  0.1056],\n",
      "        [ 3.1515,  2.0879,  1.4351,  ...,  1.2647,  0.2461,  1.7881]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "context_size=max_length\n",
    "pos_embedding_layer=torch.nn.Embedding(context_size,output_dim)\n",
    "\n",
    "pos_embedding=pos_embedding_layer(torch.arange(context_size))\n",
    "print(pos_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7371,  0.2306, -1.6115,  ..., -1.6740,  2.2484, -3.4074],\n",
      "         [ 0.5750,  0.8643, -0.2037,  ..., -0.7230,  0.9739, -1.8623],\n",
      "         [ 0.8442, -0.9500, -0.0305,  ..., -1.2798,  0.5857,  0.0661],\n",
      "         [ 3.3909,  4.3583,  2.8643,  ...,  1.1085,  1.0910,  2.3179]],\n",
      "\n",
      "        [[-0.5981, -0.6800, -0.0738,  ...,  0.4951,  1.5737, -1.5129],\n",
      "         [ 0.8636, -0.4133, -0.4366,  ...,  0.9643, -0.1109, -2.4257],\n",
      "         [-1.2988, -0.9910, -0.2506,  ...,  1.9407,  0.5146, -0.4867],\n",
      "         [ 1.9151,  2.2145,  1.4120,  ...,  3.5956,  1.2767,  1.1958]],\n",
      "\n",
      "        [[ 1.6817,  0.8673,  0.5973,  ..., -0.0594, -0.1428, -0.2399],\n",
      "         [ 1.0779, -1.7758,  1.1519,  ...,  0.5540, -2.1264, -0.1607],\n",
      "         [-0.6146, -2.1474,  0.9044,  ...,  0.3396, -0.6378,  1.3975],\n",
      "         [ 1.3510,  2.2466,  1.0229,  ...,  0.8645,  0.0751, -0.5177]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6841, -1.9304,  0.9577,  ..., -1.2288,  2.0470, -1.2654],\n",
      "         [ 1.2335,  1.2125, -0.0659,  ..., -0.7786, -1.5220, -2.0981],\n",
      "         [-1.1991,  0.1474, -0.2855,  ...,  0.6086, -0.3932, -1.1489],\n",
      "         [ 3.4758,  2.4423,  1.8921,  ...,  0.7834, -1.7984,  3.0387]],\n",
      "\n",
      "        [[ 0.3455, -2.3241, -0.4862,  ..., -1.4552,  2.4095,  1.1623],\n",
      "         [ 1.6709,  1.0193, -0.4725,  ..., -0.9035, -1.0205, -0.4516],\n",
      "         [-1.1199,  0.2589, -0.2117,  ..., -0.4642,  0.9106, -0.7474],\n",
      "         [ 2.5791,  3.2468,  0.9010,  ...,  0.7096,  0.5568,  1.9162]],\n",
      "\n",
      "        [[-0.3494, -1.8471, -0.7006,  ..., -1.4157,  2.2618,  0.1330],\n",
      "         [ 0.9554, -0.5050,  0.9081,  ...,  0.2711,  0.4686, -1.9415],\n",
      "         [-1.9161, -0.9551, -0.3760,  ..., -0.9240,  0.9121, -0.8114],\n",
      "         [ 3.1500,  1.5957,  1.7925,  ...,  1.3994,  0.1166,  1.5580]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_embedding=input_embedding+pos_embedding\n",
    "print(input_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
